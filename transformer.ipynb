{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca33dc78-9677-470e-85a6-9fab643b2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(_file):\n",
    "    try:\n",
    "        with open(_file, 'r') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58bdcba-40ff-42c9-be63-d178fce61402",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = read_file('/Users/UI0627/Projects/genai/input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a18696-9502-4515-b381-a965cb41e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case vocab is character level\n",
    "# In practise, it can be word, or sub-word (token) level\n",
    "def get_vocab(contents):\n",
    "    uniq_chars = set(contents)\n",
    "    vocab = sorted(list(uniq_chars))\n",
    "    # print(\"\".join(vocab))\n",
    "    # print(len(vocab))\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab(contents)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c712e354-954c-491b-9e49-e7b3a89bfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define encoder and decoder functions\n",
    "# Alternatives: Open-source variants. For example, GPT uses tik-token library\n",
    "\n",
    "encoder_map = { ch: i for i, ch in enumerate(vocab) }\n",
    "decoder_map = { i: ch for i, ch in enumerate(vocab) }\n",
    "\n",
    "def encoder(str):\n",
    "    return [ encoder_map[ch] for ch in str ]\n",
    "\n",
    "def decoder(idx_arr):\n",
    "    return \"\".join([ decoder_map[idx] for idx in idx_arr ])\n",
    "\n",
    "# sample_arr = encoder(\"Hello!\")\n",
    "# back = decoder(sample_arr)\n",
    "# print(sample_arr, back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4280a736-4066-42b1-b56e-d47920c2ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encoder(contents))\n",
    "\n",
    "# print(data.dtype, data.shape)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a4be30-8059-470d-b7ac-f084fa50993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to Training and Testing Data\n",
    "\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    split_point = int(len(data) * split_ratio)\n",
    "    train_data = data[:split_point]\n",
    "    test_data = data[split_point:]\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(data)\n",
    "# print(len(train_data), len(test_data))\n",
    "# print(train_data[:10], test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f02cfd2-b331-4526-b2cf-9900106626a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any transformer is never fed entire data directly, that is computationally expensive\n",
    "# So, data is fed in chunks or blocks\n",
    "\n",
    "# Time dimennsion\n",
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "738a6bb1-73fc-460a-a333-514cbeae1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, given that our Systems can work on multiple things at same time\n",
    "# We want to feed transformers multiple chunks at same time\n",
    "# This value depends on how good GPU is\n",
    "\n",
    "# This is parallelism\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b77d033-d3af-420b-b439-6a375f885b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def get_batches_v1(data):\n",
    "\n",
    "#     # Get a random index from data\n",
    "#     random_idx = random.randint(0, len(data) - block_size)\n",
    "#     x = data[random_idx:random_idx+block_size]\n",
    "#     y = data[random_idx+1:random_idx+block_size+1]\n",
    "\n",
    "#     return x, y\n",
    "\n",
    "# # get_batch(train_data)\n",
    "\n",
    "# def get_batches(data):\n",
    "\n",
    "#     x = []\n",
    "#     y = []\n",
    "\n",
    "#     for _ in range(batch_size):\n",
    "#         batch_x, batch_y = get_batch(data)\n",
    "#         x.append(batch_x)\n",
    "#         y.append(batch_y)\n",
    "\n",
    "#     return x, y\n",
    "\n",
    "\n",
    "# If you want same random numbers every time\n",
    "# torch.manual_seed(234)\n",
    "\n",
    "# Alternative Tensor version for same\n",
    "def get_batches_v2(data):\n",
    "    random_idx = torch.randint(len(data) - block_size, size=(batch_size,))\n",
    "    x = torch.stack( [data[ix:ix+block_size] for ix in random_idx] )\n",
    "    y = torch.stack( [data[ix+1:ix+block_size+1] for ix in random_idx] )\n",
    "    return x, y\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    return get_batches_v2(data)\n",
    "\n",
    "# xb, yb = get_batches(train_data)\n",
    "xb, yb = get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76f0e314-25a0-4fc6-a706-6dd07e301e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim=None):\n",
    "        super(BigramModel, self).__init__()\n",
    "\n",
    "        if embedding_dim is None:\n",
    "            embedding_dim = vocab_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # Idx should be Batch X Time dimesions\n",
    "        logits = self.embeddings(idx) # this should return Batch X Time X Embedding (channel)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=1):\n",
    "        \"\"\"\n",
    "        Generate new tokens based on the input idx\n",
    "        \"\"\"\n",
    "\n",
    "        # IDX is in Batch X Time\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "            # Get the logits for the last token\n",
    "            logits, loss = self(idx)\n",
    "\n",
    "            # Focus only on last stuff\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            # Multiple ways of generating new stuff\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            # 1. Get the most likely token\n",
    "            # idx_next = torch.max(probs, dim=1)\n",
    "            # 2. Pick one from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Append the new token to the idx\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64bd9938-2de6-414d-bd4b-aa7fd4d5bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promise.EbZJk\n"
     ]
    }
   ],
   "source": [
    "model = BigramModel(vocab_size)\n",
    "# logits, loss = model(xb, yb)\n",
    "# print(loss)\n",
    "\n",
    "print(decoder(model.generate(xb, 5)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0d5eddd-a50d-4f4e-9bc9-300f1f5bc4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.520458459854126\n",
      "2.485140085220337 0\n",
      "2.56502366065979 100\n",
      "2.5035088062286377 200\n",
      "2.4271862506866455 300\n",
      "2.3636176586151123 400\n",
      "2.396932363510132 500\n",
      "2.363022804260254 600\n",
      "2.467040538787842 700\n",
      "2.3500454425811768 800\n",
      "2.5277249813079834 900\n"
     ]
    }
   ],
   "source": [
    "# Copying this line - I dont know yet what this does\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "test_d = torch.zeros( (1, 1), dtype=torch.long)\n",
    "\n",
    "def train():\n",
    "\n",
    "    for steps in range(1000):\n",
    "        xb, yb = get_batch(\"train\")\n",
    "\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if steps % 100 == 0:\n",
    "            print(loss.item(), steps)\n",
    "\n",
    "    return loss\n",
    "\n",
    "print(loss.item())\n",
    "loss = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aa4f892f-c72b-4ded-a53d-ad5866ae12c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4259490966796875\n",
      "\n",
      "NUS:\n",
      "RUS:\n",
      "Sthed m My ppalicouromy hom hes.\n",
      "an lawin ceres: f nopesindom f d? y s at it OLAn frilin ll he: u th,\n",
      "ANOnce il tir heds:\n",
      "Je:\n",
      "\n",
      "Wistlant the,\n",
      "YON wa hithe lle t tina my s ARo sta mbe chor watan t vetoam wi knd,\n",
      "ABuirs y areredouis surato o thencindeit oile ben We akist thig urinoutoof chng tr ize:\n",
      "agrd b sn t Wha s.\n",
      "TENENuroves tholely\n",
      "Fit cherd w me the, echourirores RKICOucce t\n",
      "'ss;\n",
      "\n",
      "ARYOMavioute ge hantut:\n",
      "Whthaus INGo ther t ad s:\n",
      "Anomely pril aken;\n",
      "F Jar lllver ta tobessere venewe to bert t't omithingoureerorllighorille r ig ferif eponghe f iser st;\n",
      "I gho:\n",
      "\n",
      "ME:\n",
      "\n",
      "Ande ad mexscot nor LAn in, pais:\n",
      "I h viveerol Yorothay ond hathare d whalo tse y,\n",
      "T:\n",
      "Wid he\n",
      "\n",
      "\n",
      "\n",
      "USotitlime nclke g p llloetre\n",
      "TE:\n",
      "UTHUSockn\n",
      "ARivinthizerur ave R:\n",
      "Hererizid s LO:\n",
      "Ay bousondintesthu ghnus me ndur n rly flikiraniowhare.\n",
      "WI nso herdarit cay, g so jufind lot yor ar'seng purenoofteel ex s OUSes. brie?\n",
      "Seant OLERENCHed pp bry thit 'se bon hurm s ws t il;\n",
      "Sendes\n",
      "Yor aithuens th mean'sootstthy tes mea pre I we ans ds t s tous are. isethiet.\n",
      "K:\n",
      "\n",
      "\n",
      "Thof totleay, bize m llet ouerothal; n s bursimet, rthangh:\n",
      "We.\n",
      "Hombr,\n",
      "Se ans, LUpree s; atoular?\n",
      "Wer thathes or.-he terd,\n",
      "Gotandotuim ARLan s owowauto ore:\n",
      "And ttather n,\n",
      "Boch\n",
      "ICl, t Maviveiut, owinerest toreldedo t e m ad othanet, ime\n",
      "Wins wie sbllal touisprvestisph t m teslaredofos mowhelldisgep, liead n GBore a it atre bl bs d tugref wofu SIst tad.\n",
      "ARDends nd\n",
      "\n",
      "\n",
      "RK:\n",
      "\n",
      "Fime t.\n",
      "ORiaversal p t ingowouantheapp f who,\n",
      "mo, ndittousur avey'dinghene thil myo funethieay d pld o hyore domy ay frou BR weenil taw tsee apasakellloo?\n",
      "Anobrgo, s ovesat mond, ys the, lthatr:\n",
      "Cisothan,\n",
      "A lll op y?\n",
      "WAThar's, ou! to l that.\n",
      "Fld t,\n",
      "He:\n",
      "IUK: h prd,\n",
      "The be tount Y thuss ly, that towar WARig t se; t, al artof on tinthiathenelot s,\n",
      "T:\n",
      "\n",
      "LIETUETie.\n",
      "COf,\n",
      "Thichatenke soust bse aveererem. bigougre mind, t s t l foud;\n",
      "'t at fis bee, I toge se; IZWextwil thisthene Cinkeirt mel che onte\n",
      "\n",
      "\n",
      "AUS:\n",
      "\n",
      "Th, EEThr cipindr Boy sartarserit CAnd lld y fompo tchandeamy d wis ty aveyo manckedoctritow bll g fu t we fove thtise mesest!\n",
      "COx'deedshe\n",
      "Baren te g s wr bech s, cemema doutates? ur t\n",
      "MENGLI RAndelcowis ris onsingetodsudmy bef a arl dounpl, Lathing sors fove.\n",
      "d,\n",
      "\n",
      "D mutl okine CHout.\n",
      "CLI bly RYORI they s; mione.\n",
      "\n",
      "\n",
      "\n",
      "JO: ilesinghed arans alle thels g wiver\n",
      "Fldis gry cha f r hen theamere; my m yorden, r.\n",
      "Non y ntak!\n",
      "CLAhthe f thedelo ad plays, K: oe t:\n",
      "L:\n",
      "o e th,\n",
      "ORO:\n",
      "SI e ous,\n",
      "Lesall, se l.\n",
      "Trar;\n",
      "LANGoorollco tlis y Youryome.\n",
      "UE m ne an payoun than:\n",
      "me.\n",
      "Pl st tht avecoun'lesitheiour oy fo th at Cllad rinofe thagag rst fo d weses core he bt?\n",
      "US:\n",
      "Ty s, e y-\n",
      "\n",
      "\n",
      "\n",
      "ULousar?\n",
      "Wh ow'sstindd CHA fe lerif s\n",
      "\n",
      "ISous.\n",
      "Dods thas nomeamur:\n",
      "ARKIVI ait flo it oint h thiar, th upushale y de s fere il e.\n",
      "Cl t, m bur agn enow'Thur therengean hicouncke INIULOMENENVOMur ws te!\n",
      "Frent to llesin, I t,\n",
      "\n",
      "Yedireroubevinshy y;\n",
      "Thof Wo ounortway!\n",
      "S:\n",
      "ES:\n",
      "I sh tse pthin:\n",
      "HAUS:\n",
      "Noonekely yir meaithioy ghe, hy foeasen, s; ngoms, I:\n",
      "\n",
      "MEanfan ang,\n",
      "Whan,\n",
      "\n",
      "\n",
      "Bef he ve\n",
      "anend t cod, s ng:\n",
      "\n",
      "N thodefome thinesthond\n",
      "OUCLe br:\n",
      "\n",
      "Ay.\n",
      "He ceve migh dy; he f s f oue mamyouentoo hourothanl l'e more.\n",
      "KI t\n",
      "Bur, ourand I ththes'e se ss.\n",
      "\n",
      "\n",
      "BYourughind,\n",
      "eatotus send t te dafithithusubursand breate ourancqure fre toon hoous y, thooustofeayou, w:\n",
      "Therest w;\n",
      "OFRInghe,\n",
      "\n",
      "\n",
      "\n",
      "Whesougerin bsiorinen BRIEDWed f:\n",
      "Haf ty wi' t d?\n",
      "K:\n",
      "Anthshel my, Myor d.\n",
      "INOR:\n",
      "Au h win haiveant uches.\n",
      "The d?\n",
      "Thare, tce, nd, YONI:\n",
      "\n",
      "ty.\n",
      "Thusepofouthithib'd ty fthe brve bousstas s,\n",
      "T: thothee, amy, bay om.\n",
      "Thares inof tourinirontr\n",
      "I th miu mewar hibjofrean, V:\n",
      "M:\n",
      "Hese wo,\n",
      "Mer s headononghertrsh ig this l, theamecowor ids mevedsthimuge.\n",
      "Thul thitearachen t: thanoved nde ou h w,\n",
      "\n",
      "Anve,\n",
      "'\n",
      "Yours fre amyon oorero bjer thave-SThe lered we'd f wore ofarard s ond avepre angelend wher isats his segouldss OREThice hepoulor:\n",
      "ENUS:\n",
      "Lefindangis tofome, m.\n",
      "Whucerate ur LAnoudstholes terk pemple aghe f moust.\n",
      "And t\n",
      "ABe thith!\n",
      "\n",
      "\n",
      "Y:\n",
      "Anghesid;\n",
      "Wh IS f apove, be mige y'\n",
      "I:\n",
      "bout\n",
      "\n",
      "An t ullagrour th rat horey!\n",
      "Grs, oumus! r ingr:\n",
      "Whe te frs wem.\n",
      "He fod I chourgosanthu wa m ng ot k m w f LAMe s t cerr:\n",
      "USThey, ndsabeay, mas o, K:\n",
      "KIfr rout, ghofovice loread jut cce y Bal oud te ungr?\n",
      "\n",
      "INTUMEd meme mur.\n",
      "Hanthe I th illomave?\n",
      "LEOHatr me wal ge p be I and ISofu ay d,' bl s u tes, gho t y t ain r's ld thay,\n",
      "ABe t fal ppe.\n",
      "Prvelourehie my:\n",
      "ORUSolin CIUM:\n",
      "\n",
      "Th cieaneaven, br f By ionge aso mesathistou He appremath.\n",
      "NDY:\n",
      "FFFobesther-s! ttthishal ne bo!\n",
      "I:\n",
      "Tou ee courthernged l the, m\n",
      "BOf ps K:\n",
      "Burswaceeausher yo ur.\n",
      "BRWenghore pprkehichof te;\n",
      "Civece, t t oullsolipitle mpe a wave t ord we ms y whasord my len, s ERoususe\n",
      "LAneanthoton skiscuses uedy ive t\n",
      "St ire weret ollilard ten II t arearow t.\n",
      "Thicrr dlvesthacaverence.\n",
      "TUSO My nghisour'er cel or ches hoor wes t t'donouct a cou,\n",
      "Th thall ly, fomyor.\n",
      "ourkenge BE: hyaknese.\n",
      "BRIIUSAnitane tothe'se llamenore wieat ceieanorr weinivecace swhe pourevir, l m hathy t lla muco IFatother, d trevimep tinfo ow lk.\n",
      "\n",
      "KE youghathibene tes br I Se te te d s;\n",
      "ARI g ull ld, t ma harel s alo me t wh I Muscthe IA PURI nvequffoyis itan thoumy hyoat ir t hathe;\n",
      "I stes,\n",
      "Ye, imy tist ars. t w, melll EO w rt n s ked pr keld;\n",
      "ORime sepecewo dr; I ps h cke wheor SIUplerolffure?\n",
      "ICI cto CUSI nthan ngaikneve beodesa fad be, EEROKI ifo t d too.\n",
      "MEESII CHES:\n",
      "MI hem,\n",
      "\n",
      "GBos tok satyouth e brtheitee blatrds oru bes,\n",
      "Hay f njevero?\n",
      "thad brs n:\n",
      "Rie tistro r w r s myensthe me y t ais s th k f Doorur adsus y wene tare.\n",
      "Whidondg. IS: inofon\n",
      "An,\n",
      "hat,\n",
      "\n",
      "\n",
      "Be sebugeadir,\n",
      "Thnd hougouguchaf s s?\n",
      "OKE:\n",
      "The,\n",
      "Whirme my win pol l.\n",
      "Cof un lus hew lus o I lmes thrn eg my t tee ps ty the.\n",
      "INChiter hinod y fes tsp I iswoitner d f g swertr\n",
      "Bukeete;\n",
      "Any aveoonthand t, cowow,\n",
      "Mimim, wn id se d?\n",
      "\n",
      "G nd pu uth Incenones orat;\n",
      "Le ayo nd,\n",
      "Roer D cars pr too s,\n",
      "RETh on! m bact\n",
      "ANCKI'd. w ht, s meesisupo ug.\n",
      "\n",
      "\n",
      "\n",
      "Whilt oit, I:\n",
      "Su the st;\n",
      "CINGoushait thans;\n",
      "D:\n",
      "Tur, m ks SSI oun\n",
      "G serd, mildis es ser Canthig athe aulowne Rue owercathead'd Bupre t t olincited be thaixt s ousu wis see Tispar l hallllit\n",
      "Thety I ven od m, d cil\n",
      "I p bodsousthathen be hy heardwo scte Whart nd se IONin his reris?\n",
      "MAMacrasequnthendrnd:\n",
      "\n",
      "Cal.\n",
      "\n",
      "QUME:\n",
      "Mu ansardo fllarasthon tt acel thaveve\n",
      "\n",
      "Te youlkilles as, f aswaicitoitrt ateobe fuls CUS:\n",
      "the mou bemat n tothe teale-hodu VOMNove w thave,\n",
      "VOFRESend ws t whyore thy Jus o,\n",
      "Man:\n",
      "Wemiranty s geag.\n",
      "Bu hence marth;\n",
      "Font\n",
      "Fondassushanousouriroullenmbin weersher ped al\n",
      "Toooulcll pin s ol hinorengor'sothtatey.\n",
      "NIn fryorse ll.\n",
      "YOfe:\n",
      "Fo brtoulouredite?\n",
      "Ghefay h s thansalapols f ar.\n",
      "I wheld tharft,\n",
      "Mame s.\n",
      "DWengher byo chtiffearcodelld:\n",
      "G e yo! t d onve whert de tud dy th thyoreeando, foour thap Hiny, y odo t ncos.\n",
      "\n",
      "Than bu w owed aty, shil hesilthalo'tivemarefancagosh resl o tnd brer'd he wof a tanff f thagond t y uedouid, leiner,\n",
      "D: s Bysthamis.\n",
      "\n",
      "Whongil-lviniringare.\n",
      "My an I sud theubese, y so thetu wbe arasin'de woul'\n",
      "Bee, bod AUT:\n",
      "T:\n",
      "sit yeitis\n",
      "Ancowathak andstom,\n",
      "He.\n",
      "MENULoff I sw MENDUStwore betofato alispan or ms ul; pomowh OLomofrost sig ncotse hes:\n",
      "MERiro me, hes ble, antrrofofeain dsll'dily!\n",
      "\n",
      "A har EThtrin orsof II hthad, wig t ol, warn thisembo nd tharesofis;\n",
      "Horndany'd awile me thobe thaurerou we\n",
      "BEThefare'thalladoy hes suray.\n",
      "Tott t ho lander excers t stwik t t.\n",
      "Thengred al'd, our, atsd ld m bl tthe\n",
      "D BRTheenof he, s hernin pe t my t woastre perd che irknd;'s be t fite:\n",
      "\n",
      "Thicond w d wnsat\n",
      "Cot tel cle, withepptas.\n",
      "\n",
      "ARYBusharakely cad ilorw-hinghe blinoutherath n f mad\n",
      "\n",
      "Whe k'l--\n",
      "OMy.\n",
      "Tofouneth too ARD:\n",
      "The tandid-sin pu gushaitacond, tshed the tu s s ithe thicerot toun,\n",
      "\n",
      "Fisth itr pro G t, tis d!\n",
      "LAn, lyis miris gesmo thee mbe y chith m wentod w.\n",
      "As bak ted ad bur Tokerstha m!\n",
      "WI ren mestran d d serim icewainke's ten;\n",
      "\n",
      "VI moreno---\n",
      "BOR: qu wrou owhil spauery t sterard the INUThage fou byothothagaturdyicharingoto'sowilthe, Pl, cowhe winsk lpaloutierd, d eey hize, ces, mor.\n",
      "\n",
      "Wher Ir th's t reyithas s bbe hathere.\n",
      "'dsplle REThakiciscke pidule OM:\n",
      "RYorsyorent JUThat se t t TI' H: wiow ghaghr te hores t athat, hee Fr foou dind tyr dwn spth pechithailal.\n",
      "\n",
      "Whar d, byour andalaremy ur,----dow'd'ly tous?\n",
      "Bre bo haprd the mpabowik sthoowico bechof d.\n",
      "I\n",
      "Whoure akneend OMukshowntr mar l,\n",
      "ENRDWin:\n",
      "Ducay morertngrathy,\n",
      "Whin I myoorst IAg\n",
      "Thave apoiveroud T:\n",
      "A ve my therederantwoundfer the thealilcead ty blthar:\n",
      "KIUNGad wa blin'dst t RD OFitshamof than ar INING ins chy cothing celoay s andllentthago'sincknd mas Ro holondork le m toonos ENI t'd thaun atie anus. m, h:\n",
      "YOFONI t iam ur:\n",
      "Shepr, bookers t,-am.\n",
      "INGLo d thoonee.\n",
      "ben, k gme!\n",
      "TUK:\n",
      "Ale n stopppatounis lld abe!\n",
      "A he wheatr\n",
      "GBR:\n",
      "QUSedatherca heghondetouplaran:\n",
      "Mabouith fr s ourat ooutllll, w hothouesplantonjot the f?\n",
      "ARolleshy ngad ct I cuck w w l.\n",
      "Sh oueant arecomailathan? mbrexcho arbang kunde f hat, je ds tis a f ilpr ou yeon.\n",
      "USThe, son;\n",
      "\n",
      "Whe:\n",
      "An RD:\n",
      "Woreatho chof tiled?\n",
      "\n",
      "I re ngd, t dures\n",
      "Plyo, than: ls embr ale pe su,\n",
      "Twn Y aysthe be, obagr dwine belit te; it; stive the r wng wely hingr wous ilodst s ayow sethequr Hear ander art ur cef fous h pe. s mer's cks p hethaldy cod fether,\n",
      "AUS:\n",
      "Win tthinjul\n",
      "Totey inout thyoot\n",
      "\n",
      "WI teayo n ulche-ped; XE:\n",
      "I dy a an o cus, d alend thotoupearean wad te ho by y, win out\n",
      "PRoureaid'tll ct:\n",
      "QUT:\n",
      "\n",
      "BUnatatiepr AR d t s?\n",
      "Whmpe.\n",
      "DI Gowheerry kize y kitomy, sacclyithe en ntin.\n",
      "I acappanis t lico firges.\n",
      "NGLA ther l hieresty sirt eay n hmy, me ugry imy ayon d, t, thencakes anaror,\n",
      "VINDonk'spswhe o, But nd VIUS:\n",
      "KIORiouke at'se tontrasillodanthagou ' thirshaklingl sckeato yorinedewst l balo mathreankito'swivite me n w, wertcinaileands iseto so is.\n",
      "HBRDulfour, he pen h t, tanthallfronday sh ut g l pr'llarconanoul, feruthal t heatede sins the iginss henieth howed bsum arde I, brcubure fighe hy t thinchel eswa Whtot by thic hu e awh hephe fatlinthin:\n",
      "RLKI wole ber at,\n",
      "KEN thin prchedath uritey haco bredetrad r fens s d r wn thall: s cougay,\n",
      "\n",
      "BINDI t meema rast trt ros wondar, iengitharothond br, helequeneads, thead muee RKEdotinoutor theie ctun, selomeno wow h bokng are!\n",
      "\n",
      "\n",
      "Was y ts\n",
      "GLI wousthameveniow est CEx fallyomo theatrag otis\n",
      "JUETES:\n",
      "\n",
      "\n",
      "Wel t liedet mase espovor iseyod w ha\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())\n",
    "print(decoder(model.generate(test_d, 10000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
