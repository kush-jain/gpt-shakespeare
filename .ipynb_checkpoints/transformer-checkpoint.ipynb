{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca33dc78-9677-470e-85a6-9fab643b2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(_file):\n",
    "    try:\n",
    "        with open(_file, 'r') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58bdcba-40ff-42c9-be63-d178fce61402",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = read_file('/Users/UI0627/Projects/genai/input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a18696-9502-4515-b381-a965cb41e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case vocab is character level\n",
    "# In practise, it can be word, or sub-word level\n",
    "def get_vocab(contents):\n",
    "    uniq_chars = set(contents)\n",
    "    vocab = sorted(list(uniq_chars))\n",
    "    # print(\"\".join(vocab))\n",
    "    # print(len(vocab))\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c712e354-954c-491b-9e49-e7b3a89bfb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 2] Hello!\n"
     ]
    }
   ],
   "source": [
    "# Now lets define encoder and decoder functions\n",
    "# Alternatives: Open-source variants. For example, GPT uses tik-token library\n",
    "\n",
    "encoder_map = { ch: i for i, ch in enumerate(vocab) }\n",
    "decoder_map = { i: ch for i, ch in enumerate(vocab) }\n",
    "\n",
    "def encoder(str):\n",
    "    return [ encoder_map[ch] for ch in str ]\n",
    "\n",
    "def decoder(idx_arr):\n",
    "    return \"\".join([ decoder_map[idx] for idx in idx_arr ])\n",
    "\n",
    "# sample_arr = encoder(\"Hello!\")\n",
    "# back = decoder(sample_arr)\n",
    "# print(sample_arr, back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4280a736-4066-42b1-b56e-d47920c2ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([746442])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# Convert to Tensor\n",
    "import torch\n",
    "\n",
    "def get_tensor_representation(arr):\n",
    "    return torch.tensor(arr, dtype=torch.long)\n",
    "\n",
    "data = get_tensor_representation(encoder(contents))\n",
    "\n",
    "# print(data.dtype, data.shape)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0a4be30-8059-470d-b7ac-f084fa50993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671797 74645\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) tensor([52, 43, 43, 42, 57,  1, 39, 40, 47, 42])\n"
     ]
    }
   ],
   "source": [
    "# Convert dataset to Training and Testing Data\n",
    "\n",
    "def split_data(data):\n",
    "    split_point = int(len(data) * 0.9)\n",
    "    train_data = data[:split_point]\n",
    "    test_data = data[split_point:]\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(data)\n",
    "# print(len(train_data), len(test_data))\n",
    "# print(train_data[:10], test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f02cfd2-b331-4526-b2cf-9900106626a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any transformer is never fed entire data directly, that is computationally expensive\n",
    "# So, data is fed in chunks or blocks\n",
    "\n",
    "block_size = 8\n",
    "\n",
    "# Now, what this block size means how many prediction NN can make for one iteration\n",
    "# For example 18, 47, 56, 57, 58,  1, 15, 47 \n",
    "# --> In this \n",
    "#     Given 18, predict 47\n",
    "#     Given 18, 47, predict 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "738a6bb1-73fc-460a-a333-514cbeae1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, given that our Systems can work on multiple things at same time\n",
    "# We want to feed transformers multiple chunks at same time\n",
    "# This value depends on how good GPU is\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b77d033-d3af-420b-b439-6a375f885b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def get_batch(data):\n",
    "        \n",
    "#     # Get a random index from data\n",
    "#     random_idx = random.randint(0, len(data) - block_size)\n",
    "#     x = data[random_idx:random_idx+block_size]\n",
    "#     y = data[random_idx+1:random_idx+block_size+1]\n",
    "\n",
    "#     return x, y\n",
    "\n",
    "# # get_batch(train_data)\n",
    "\n",
    "# def get_batches(data):\n",
    "\n",
    "#     x = []\n",
    "#     y = []\n",
    "\n",
    "#     for _ in range(batch_size):\n",
    "#         batch_x, batch_y = get_batch(data)\n",
    "#         x.append(batch_x)\n",
    "#         y.append(batch_y)\n",
    "\n",
    "#     return x, y\n",
    "\n",
    "\n",
    "# If you want same random numbers every time\n",
    "# torch.manual_seed(234)\n",
    "\n",
    "# Alternative Tensor version for same\n",
    "def get_batches_v2(data):\n",
    "    random_idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack( [data[ix:ix+block_size] for ix in random_idx] )\n",
    "    y = torch.stack( [data[ix+1:ix+block_size+1] for ix in random_idx] )\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# xb, yb = get_batches(train_data)\n",
    "xb, yb = get_batches_v2(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd9938-2de6-414d-bd4b-aa7fd4d5bbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
